{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "062b3678-aa78-470e-9d3d-84c7df028533",
   "metadata": {},
   "source": [
    "# Train model\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce817e65-ace5-4ef6-9dfa-bce74350e8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jorge/.conda/envs/splice-junction/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Default python libraries\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# Third party\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "\n",
    "# Local imports\n",
    "\n",
    "from src import (\n",
    "    DataGenerator, \n",
    "    ModelLoader, \n",
    "    EncoderOutput,\n",
    "    DecoderOutput,\n",
    "    HotEncoder, # for each nucleotide basis\n",
    "    HotEncoderKmer, # for kmers\n",
    "    Word2Vec, # for kmers represented vector embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd556452-77c2-4390-9d29-cf705bd9462b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix seed\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1e505e-a3b7-48e8-9142-160600a81b4d",
   "metadata": {},
   "source": [
    "## Basic config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "071ea3a6-7a60-47fc-ab6b-c2c3386112a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save train results\n",
    "PATH_TRAIN_RESULTS = Path(\"train_results\")\n",
    "PATH_TRAIN_RESULTS.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14a31f53-7670-4012-b470-fbc374567375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basepath, to access 01-... and 02-... folders\n",
    "BASEPATH = Path().cwd().resolve().parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30321f77-d40c-4e0a-9380-b65a1615fe4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instantiate some classes\n",
    "# load architectures defined at ./src/models\n",
    "model_loader = ModelLoader()\n",
    "\n",
    "# encode input sequence \n",
    "encoder_input = Word2Vec(k = 3, s = 1, size_emb = 20) #HotEncoderKmer(k=3)\n",
    "\n",
    "# encode labels\n",
    "encoder_output = EncoderOutput(order_output_model=[0,1])\n",
    "\n",
    "# translate output model to labels\n",
    "decoder = DecoderOutput(\n",
    "    order_output_model = [\"No-Splice-Junction\", \"Splice-Junction\"],\n",
    "    argmax = True,\n",
    ")\n",
    "\n",
    "# Batches configuration: (batch_size, len_\n",
    "batch_size = 32\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1c1d56-2286-48f9-82c5-3665436b2caf",
   "metadata": {},
   "source": [
    "### Datasets\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bbbcbb9-551f-493d-a123-6a6438afa540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets info\n",
    "with open(BASEPATH.joinpath(\"01-data-preparation/data/datasets.json\")) as fp:\n",
    "    datasets = json.load(fp)\n",
    "\n",
    "# Load sequences data\n",
    "PATH_DATA = Path('/home/jorge/AlgoLab/Tezi-Marzi/Tezi-Documentation/Master Thesis-20210607T163207Z-001/Master Thesis/Archive')\n",
    "data = pd.read_csv(PATH_DATA.joinpath('Sequences_chr1_unique.csv'))\n",
    "sequences_by_id = {ID: seq for ID, seq in zip(data.index, data.Sequences)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faf7b916-c77d-4b3a-a657-5fb36fd777d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_labels = datasets[\"id_labels\"] # rows in the dataframe \n",
    "labels    = datasets[\"labels\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4eda591-17e3-4fce-9ee2-337f19a6f492",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = DataGenerator(\n",
    "    sequences = [sequences_by_id.get(ID) for ID in id_labels.get(\"train\")], \n",
    "    labels    = labels.get(\"train\"),\n",
    "    encoder_input = encoder_input,\n",
    "    encoder_output = encoder_output,\n",
    "    batch_size= batch_size,\n",
    ")\n",
    "\n",
    "val_generator = DataGenerator(\n",
    "    sequences = [sequences_by_id.get(ID) for ID in id_labels.get(\"val\")], \n",
    "    labels    = labels.get(\"val\"),\n",
    "    encoder_input = encoder_input,\n",
    "    encoder_output = encoder_output,\n",
    "    batch_size= batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82fd3b2-9a78-444c-810b-ab4714cc1dd3",
   "metadata": {},
   "source": [
    "### Model config\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "050b1932-091c-45d4-9e6d-66fc73cb9ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model to use\n",
    "model_name   = 'cnn_3-mer_60-seq_20-emb'\n",
    "weights_path = None # None means that random weights will be used to initialize the net\n",
    "output_layer = 'softmax' # activation function of last layer, 'sigmod' or 'softmax'\n",
    "n_output     = 2 # neurons in last layer. None -> default to len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "402e3ac5-faf2-43e8-bc5c-08359d20bc9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 58, 20), (32, 2))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,y = train_generator.__getitem__(1)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0e7f7b3-ef79-46be-908f-02aefa9f51b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=tf.keras.optimizers.Nadam(\n",
    "    learning_rate=0.003, \n",
    "    beta_1=0.9, \n",
    "    beta_2=0.999, \n",
    "    epsilon=1e-07, \n",
    "    name=\"Nadam\"\n",
    ")\n",
    "name_reference_optimizer = \"nadam\"\n",
    "\n",
    "# Loss\n",
    "loss = \"binary_crossentropy\"\n",
    "name_reference_loss = \"binary_crossentropy\" #Name to use in training_config put in the dictionary (needed when using a custom loss)\n",
    "bool_weighted_loss = False # True: use weighted loss using training set\n",
    "\n",
    "# Metrics\n",
    "metrics=[\"accuracy\"]\n",
    "name_reference_metrics = [\"accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45917129-9070-4d7c-86e9-0e3430f1b16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo 'conv_3-mer_60-seq_20-emb' cargado correctamente\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model_name = \"conv_3-mer_60-seq_20-emb\"\n",
    "model_loader = ModelLoader()\n",
    "model = model_loader(\n",
    "            model_name   = model_name, \n",
    "            n_output     = n_output,\n",
    "            output_layer = output_layer,\n",
    "            weights_path = weights_path,\n",
    ")\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8eeaa97-171c-4695-9dac-03590b20e7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 58, 20)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 58, 128)           18048     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 58, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 58, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 29, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 29, 64)            57408     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 29, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 29, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 15, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 15, 32)            14368     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 15, 32)            0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 15, 32)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 8, 32)             0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 122,978\n",
      "Trainable params: 122,978\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2037f6f3-86bd-42ee-9fa6-f4a6ec14b62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save architecture\n",
    "model_json = model.to_json()\n",
    "architecture = f\"architecture-{model_name}-{output_layer}.json\"\n",
    "with open(PATH_TRAIN_RESULTS.joinpath(architecture), \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f66f8f9-6e58-4aa2-a41d-b2ad76ed5acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "** class_weights None\n",
      "\n",
      "Epoch 1/100\n",
      "1578/1578 [==============================] - 48s 29ms/step - loss: 0.6967 - accuracy: 0.5418 - val_loss: 0.6751 - val_accuracy: 0.5978\n",
      "Epoch 2/100\n",
      "1578/1578 [==============================] - 45s 28ms/step - loss: 0.8952 - accuracy: 0.5588 - val_loss: 1.0519 - val_accuracy: 0.4971\n",
      "Epoch 3/100\n",
      "1578/1578 [==============================] - 43s 27ms/step - loss: 0.6986 - accuracy: 0.5199 - val_loss: 0.6834 - val_accuracy: 0.5626\n",
      "Epoch 4/100\n",
      "1578/1578 [==============================] - 42s 27ms/step - loss: 0.6790 - accuracy: 0.5684 - val_loss: 0.6720 - val_accuracy: 0.5314\n",
      "Epoch 5/100\n",
      "1578/1578 [==============================] - 45s 29ms/step - loss: 0.7629 - accuracy: 0.5599 - val_loss: 0.6457 - val_accuracy: 0.6002\n",
      "Epoch 6/100\n",
      "1578/1578 [==============================] - 44s 28ms/step - loss: 0.6676 - accuracy: 0.5902 - val_loss: 0.6477 - val_accuracy: 0.6310\n",
      "Epoch 7/100\n",
      "1578/1578 [==============================] - 47s 29ms/step - loss: 0.6694 - accuracy: 0.5921 - val_loss: 0.7370 - val_accuracy: 0.5331\n",
      "Epoch 8/100\n",
      "1578/1578 [==============================] - 44s 28ms/step - loss: 0.6781 - accuracy: 0.5858 - val_loss: 0.6422 - val_accuracy: 0.6261\n",
      "Epoch 9/100\n",
      "1578/1578 [==============================] - 45s 28ms/step - loss: 0.6778 - accuracy: 0.5827 - val_loss: 0.6478 - val_accuracy: 0.5951\n",
      "Epoch 10/100\n",
      "1578/1578 [==============================] - 46s 29ms/step - loss: 0.6770 - accuracy: 0.5865 - val_loss: 0.6428 - val_accuracy: 0.6179\n",
      "Epoch 11/100\n",
      "1578/1578 [==============================] - 45s 29ms/step - loss: 0.6771 - accuracy: 0.5895 - val_loss: 0.7493 - val_accuracy: 0.5000\n",
      "Epoch 12/100\n",
      "1578/1578 [==============================] - 45s 29ms/step - loss: 0.6814 - accuracy: 0.5822 - val_loss: 0.6215 - val_accuracy: 0.6478\n",
      "Epoch 13/100\n",
      "1578/1578 [==============================] - 46s 29ms/step - loss: 0.6816 - accuracy: 0.5796 - val_loss: 0.6990 - val_accuracy: 0.5155\n",
      "Epoch 14/100\n",
      "1578/1578 [==============================] - 44s 28ms/step - loss: 0.6804 - accuracy: 0.5842 - val_loss: 0.6637 - val_accuracy: 0.5629\n",
      "Epoch 15/100\n",
      "1578/1578 [==============================] - 38s 24ms/step - loss: 0.6818 - accuracy: 0.5802 - val_loss: 0.6780 - val_accuracy: 0.5478\n",
      "Epoch 16/100\n",
      "1578/1578 [==============================] - 46s 29ms/step - loss: 0.6814 - accuracy: 0.5835 - val_loss: 0.6632 - val_accuracy: 0.5737\n",
      "Epoch 17/100\n",
      "1578/1578 [==============================] - 43s 27ms/step - loss: 0.6817 - accuracy: 0.5817 - val_loss: 0.7684 - val_accuracy: 0.5071\n",
      "Epoch 18/100\n",
      "1578/1578 [==============================] - 45s 28ms/step - loss: 0.6853 - accuracy: 0.5799 - val_loss: 0.6484 - val_accuracy: 0.6424\n",
      "Epoch 19/100\n",
      "1578/1578 [==============================] - 44s 28ms/step - loss: 0.6838 - accuracy: 0.5820 - val_loss: 0.6708 - val_accuracy: 0.5539\n",
      "Epoch 20/100\n",
      " 573/1578 [=========>....................] - ETA: 26s - loss: 0.6823 - accuracy: 0.5861"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-956648e62f5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m history_train = model.fit(\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/splice-junction/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/splice-junction/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/splice-junction/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/splice-junction/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/splice-junction/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.conda/envs/splice-junction/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/splice-junction/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Callbacks\n",
    "# ModelCheckpoint\n",
    "weights_file = f'{PATH_TRAIN_RESULTS.as_posix()}/weights-{model_name}-{output_layer}-' + 'epoch{epoch:03d}-val_acc{val_accuracy:.3f}.hdf5'\n",
    "\n",
    "# Tensorboard\n",
    "now = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = Path(f\"logs/{model_name}-{now}\")\n",
    "log_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Callbacks\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath=weights_file, save_best_only=True, save_weights_only=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=0.0001),\n",
    "    tf.keras.callbacks.EarlyStopping(patience=50),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir=log_dir.as_posix(), histogram_freq=1)\n",
    "]\n",
    "\n",
    "if bool_weighted_loss:\n",
    "    class_weight = {0:1,1:3}\n",
    "else:\n",
    "    print(\"\\n** class_weights None\\n\")\n",
    "    class_weight = None\n",
    "\n",
    "# Train model on dataset\n",
    "# logger.info(f\"Begin training.\")\n",
    "\n",
    "# # Prueba sin generador\n",
    "# X,y=train_generator.__getitem__(10)\n",
    "# history_train = model.fit(\n",
    "#     x=X,\n",
    "#     y=y,\n",
    "#     epochs=2,\n",
    "#     validation_data=(X,y),#val_generator,\n",
    "#     callbacks = callbacks,\n",
    "#     #class_weight=class_weights\n",
    "# )\n",
    "\n",
    "history_train = model.fit(\n",
    "    x=train_generator,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_generator,\n",
    "    callbacks = callbacks,\n",
    "    class_weight=class_weight\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ca0e44-44af-46a9-a2fb-07d49bc1d286",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}